\renewcommand{\abstractname}{\textbf{{\Large Abstract}}}
\addcontentsline{toc}{chapter}{\textbf{Abstract}}

% You need to change the text for abstract
\begin{abstract}

Person re-identification (re-id) across multiple cameras with non-overlapping fields of view is one of the most significant problems in computer vision and intelligent video surveillance system. However, most of the existing re-id algorithms are designed for closed-world scenarios which consider the same descriptors across the camera network regardless the dramatic change in view angle and pose of a person due to different camera positions, eventually lead to them to perform poorly in real-world surveillance scenarios. In this thesis, we introduce an efficient  gait-based person re-identification algorithm that addresses the challenges arise from real-world multi-camera surveillance environment. Again, recognizing individual people from their walking pattern or gait in an unconstrained environment is a challenging problem in computer vision research due to the presence of various covariate factors like varying view angle, change in clothing, walking speed, and load carriage, etc. Most of the earlier works were based on human silhouettes which have proven to be efficient in recognition but are not invariant to change in illumination and clothing. In this research, to address this problem, we present a simple yet effective approach for robust gait recognition using a recurrent neural network (RNN). Our RNN network with GRU architecture is very powerful in capturing the temporal dynamics of the human body pose sequence and perform recognition. We also design a low-dimensional gait feature descriptor based on the 2D coordinates of human pose information which is proven to be not only invariant to various covariate factors but also effective in representing the dynamics of various gait pattern. For multi-view gait recognition, we also propose a two-stage network in which we initially identify the walking direction by extracting the spatio-temporal features from gait video using a 3D convolution. The experimental results on challenging CASIA A and CASIA B gait datasets demonstrate that the proposed method has achieved state-of-the-art performance on both single-view and multi-view gait recognition which prove the effectiveness of our method. 
\end{abstract}

\endinput
