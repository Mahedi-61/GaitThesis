\chapter{Literature Review} \label{ch:literature_review}
Over the last two decades, several methods have been studied to develop a robust gait recognition system~\cite{Rida_19}. In this chapter, we briefly discuss some of these techniques which can be divided into the following three main classes:

\begin{itemize}
\item \textbf{Interactive sensor-based methods:}
These methods use sensing devices such as infrared reflective sensors, a gear sport, etc. to capture specific information from the subject and use this information to analyze gait. Pressure plates or carpet is also used to measure the pressure profile of the feet during gait. In~\cite{Pogorelc_10}, the gait of a monitored subject is captured using infrared (IR) cameras in conjunction with reflective tags worn in several parts of the body to analyze several diseases like pain in the back and leg, Paraplegia, and Parkinson~\cite{Michele_17}. However, these methods are appropriate for indoor spaces and for a restricted number of activities.

\item \textbf{Motion sensor-based methods:} Wearable motion sensors such as accelerometers, gyroscopes, and magnetometers are attached to the joints of the subject's body. The displacement is recorded with respect to a reference point. Joint angle trajectories and the distance between different parts of the body during gait are then calculated and used for recognition. These methods are more prevalent in medical research and rehabilitation studies with limited discomfort for the wearer. Here, the experiments are usually done in the laboratory setup; and therefore, has limited scope.

\item \textbf{Vision-based methods:} A video is recorded as the person walks along a preset trajectory without having any sensors attached to any part of the body. The data can be recorded both indoor and outdoor using single or multiple cameras. These types of methods have a much wider scope and applications as compared to sensor-based ones. These methods can be further subdivided into two categories: marker-based and markerless methods.
	
	\begin{itemize}
		\item \textbf{Marker-based methods: } Active or passive markers are placed on the body of the subject at different joints. This helps to detect and track the motion of the desired joints in the video during gait motion. The subject usually wears black and tight clothing and then reflective markers are placed on the body joints.
		
		\item \textbf{Markerless methods: } Recognition is done in a video that is recorded with normal clothing without using any marker.  
	\end{itemize}
\end{itemize}

Vision-based gait recognition method is particularly challenging in a real-world multi-camera environment due to the large variation in camera view angle, pose, illumination, and subject’s intrinsic variations such as the change in clothing and carrying condition. Among these covariate factors,  the viewpoint variation is the most important factor which severely affects the gait recognition performance. To handle view variation efficiently, gait recognition algorithms have generally been studied under three experimental setups: single-view, multi-view, and cross-view setup. In a single-view setup, both probe and gallery gaits are kept within the same view angle, wherein cross-view gait recognition, the probe, and gallery gaits are kept in different views; and in multi-view gait recognition, multiple views of gallery gaits are combined to recognize a probe gait under a specific view.


The work proposed in this thesis falls into the vision-based markerless category. There are two main approaches in person gait recognition in markerless systems. The first approach, known as the \textit{appearance-based} approach, does not assume any prior human geometric shape. The second approach, a \textit{model-based} one, on the contrary, assumes a priori geometric shape model.

Again, in vision-based methods, to extract discriminative features for performing recognition, various input data types such as human silhouette~\cite{Han_06}, pose~\cite{Liao_17, Liao_19}, optical flow~\cite{Wolf_16}, and dense trajectories~\cite{Chen_18} have been employed in literature that are not quite robust to all covariate variations and often requires costly equipment. However, among these input data types, it has been proven that the pose information does not depend on people body appearance and hence less affected by the variation of covariate factors. Moreover, the dynamics of the human body pose can convey the temporal information of gait; therefore, it can effectively represent the gait pattern. But unfortunately, for the missing joint information in human pose estimation due to occlusion and left-right body part mixing, we often got errors while modeling the pose sequence. Nevertheless, employing recent deep learning-based algorithms in body pose estimation and proper post-processing, we can model different human body parts accurately which significantly improves the performance of pose-based gait recognition.


In this chapter, we will present a brief review of the previous works in both categories. However, with time these traditional handcrafted appearance-based techniques, as discussed in Section~\ref{sec:appearance_based_methods}, and model-based techniques, as discussed in Section~\ref{sec:model_based_methods}, are being shifted toward automated learning methods, i.e., deep learning-based methods. Section~\ref{sec:deep_learning_gait_rec} discusses some of the methods that achieved state-of-the-art results using deep learning-based algorithms. And in Section~\ref{sec:pose_based_gait_rec}, we review some of the recent pose-based gait recognition approaches that are closely related to our work. 




%-------------------------------------------------------------------------
\section{Appearance-Based Methods} \label{sec:appearance_based_methods}
The appearance-based gait recognition methods first performed motion detection to segment the regions corresponding to the moving humans. Some form of shape analysis was then applied to these image sequences to extract the gait signatures. Static body parameters such as lengths and widths of the limbs, the height of the person were extracted in some techniques and used to represent gait. Some works rely on the dynamic features that were extracted by shape changes and motion flow. Most of the previous work following this approach~\cite{Benabdelkader_02, Liu_04, Han_06, Bashir_09, Lam_11} used human silhouette masks as the main source of information and extracted features that show how these mask change. 

BenAbdelkader \textit{et. al.}~\cite{Benabdelkader_02} presented a parametric method for person identification based on the height and the stride parameters of gait from low-resolution video sequences. A non-parametric background modeling approach was adopted for the segmentation of the moving objects. Foreground blobs were then tracked using the spatial and the temporal coherence. The height and the stride parameters were determined from the extracted binary silhouettes. The experiments were performed on a database containing $ 45 $ subjects and an accuracy of $ 49\% $ was achieved by using both the stride and the height parameters and only $21\%$ by using the stride parameter only. Although they did not achieve a significant performance, yet their results showed that stride and the  height parameters may be used as potential candidates for the gait recognition system.

In~\cite{Liu_04}, Liu and Sarkar computed the average silhouette during the whole gait sequence. Their algorithm consisted of three steps. In the first step, the background pixel statistics were calculated using the Mahalanobis distance and EM algorithm. The second step calculated the periodicity of the gait by simply counting the number of foreground pixels in the silhouette in each frame over time. The pixels belonging to the leg area were used to increase the sensitivity for determining the periodicity of the gait. In the third and last step, the average silhouettes were computed. The similarity measure was defined as the negative of the median of the Euclidean distance between the averaged silhouettes from the probe and the gallery.

However, the most popular gait representation employed in appearance-based methods is gait energy image (GEI)~\cite{Han_06}, a binary mask computed through aligning and averaging the silhouettes over a complete gait cycle. Though there are many other alternatives for GEI, e.g., gait entropy image (GEnI)~\cite{Bashir_09}, gait flow image (GFI)~\cite{Lam_11}, and chrono-gait Image (CGI)~\cite{Wang_12}, due to its insensitiveness of incidental silhouettes error, it has been considered as the most stable gait features.  It can achieve good performance under controlled and cooperative environments but does not show robustness when the view angle and clothing condition change. 

In order to reduce the drastic change in the shape of GEI, Huang \textit{et al.}~\cite{Huang_12} fused two new gait representation: shifted energy image and the gait structural profile to increase the robustness to some classes of structural variations. But, the performance of this method was not good enough due to the loss of temporal information while calculating GEI. 

To preserve the temporal information, Wang \textit{et. al.}~\cite{Wang_12} modified the gait energy image and constructed a Chrono-gait image to include the temporal information. After gait period detection, they used local information entropy to obtain the gait contour from the silhouette images. Synthetic chrono-gait images were also constructed to avoid overfitting due to the smaller number of real chrono-gait images. LDA and PCA were applied for dimensionality reduction. A comprehensive experimental evaluation was reported on three major gait datasets. An average CMS value of $ 48.64\% $ and $ 66.81\% $ was achieved at rank 1 and rank 5 respectively using all 12 probe sets of the HumanID database~\cite{Sarkar_05}. These results did not show any marked improvements over the related gait energy image method.


In summary, appearance-based methods are sensitive to the covariate factors as the extraction of human silhouettes is affected by the changes in lighting. Moreover, when the shape of the human body and appearance changes substantially, the performance of these methods degrades severely. Therefore, these methods are not completely robust toward the covariate factors.



%-------------------------------------------------------------------------
\section{Model-Based Methods} \label{sec:model_based_methods}
Model-based methods~\cite{Yam_04, Gu_10, Wagg_04} are often built with a structural and a motion model to capture both the static as well as the dynamic information of gait. The salient advantage of these approaches is that, in contrast to silhouette-based approaches, it can efficiently handle the covariate factors if the human bodies are accurately modeled.

There has been a considerable amount of work on tracking the human body based on the pose and body shape. However, these techniques have not caught much attention over the past years into the research community due to the fact that tracking the human body is itself a challenging problem that involves very intensive computations. The geometrical model of the human body is usually parameterized and tracking of the shape is achieved by establishing the correspondence between model configurations and image features. The most common methods for tracking include Kalman filter, dynamic Bayesian network~\cite{Pavlovic_99}, and condensation algorithm~\cite{Isard_98}. 

The model-based approaches generally extract gait features from either the static parameters or the relative motion of joint angles. The static parameters of the human body such as torso height, leg length, and stride are calculated from fitting the model in each frame and then further analyzing it for feature extraction. The joint angle trajectories are calculated using some methods and the gait features are extracted from them. These approaches can also be distinguished by the dimension of the shape model which could be 2D or planar or a 3D model. The following paragraphs elaborate on some of the popular model-based methods for human gait recognition.


Wagg and Nixon developed a model-based method based on the biomechanical analysis of walking people and used it for recognition~\cite{Wagg_04}. The image sequences were segmented to extract the moving regions and an articulated model is fitted to the edge by a hierarchical procedure. Motion estimation was performed using a sinusoidal model for the leg and angle trajectories were then extracted. The method was evaluated by employing the SOTON database~\cite{Shutler_04}. They designed a $63$ dimensional feature vector. A recognition rate of $84\%$ on the indoor dataset and $64\%$ for the outdoor dataset was achieved.


Yam \textit{et al.}~\cite{Yam_04} developed an automated model-based approach to recognize the people using walking as well as running gait. They used a modeling technique based on the concept of coupled oscillators and the underlying principles of human locomotion. The two approaches derive a phase-weighted Fourier Descriptor (FD) gait signature by automated non-invasive means. Assuming the gait symmetry, the same model was used to describe either leg since both performed the same motion but out of phase with each other by half a period. These motions operate in space and time satisfying the rules of spatial symmetry and temporal symmetry. This model of forced coupled oscillators was fitted to the image data extracting the lower leg motion in both walking and running gait. The gait features were derived from the magnitude and phase of FDs of the thigh and lower leg rotation. Statistical analysis was also performed to find the most effective feature set. 


A 3D human body model consisting of $11$ body segments was developed by Gu \textit{et. al.}~\cite{Gu_10}. The head was represented by a sphere and other segments were cylindrical. The model contains $10$ joints with $24$ Degrees Of Freedom (DOF). The kinematic structure of the model was estimated by employing anthropometric constraints between ratios of the limb lengths. After the body segmentation, an adaptive particle filter was used to track the body segments. Gait features were extracted from the pose parameters and the joint position sequences. Two gait models were obtained from the normalized joint sequence of the whole body and the normalized joint sequence of the two legs using an exemplar-based Hidden Markov Model (\gls{hmm}). Maximum a Posteriori (MAP) estimation was used for pattern classification. The test dataset consisted of multiple video streams of $12$ subjects that were simultaneously captured from multiple static calibrated cameras. Volumetric representation sequences were created using the visual hull method after foreground extraction. An average recognition rate of $94.4\% $ was reported on the test dataset.

So, in summary, model-based approaches are generally invariant to various intraclass variations like clothing, carrying, and view angle, etc. But the main drawback of this approach is that the extraction process of human body parameters like the height, knee, and torso are computationally expensive and highly dependent on the quality of the gait video. Recent advancement of the pose-estimation algorithms in computer vision using deep learning-based methods~\cite{Cao_19, Wei_16}, however, make it possible to estimate the poses of multiple people in real-world low-resolution images with higher accuracy and low computational cost. The success of these algorithms opens the door to retake these approaches for robust gait recognition. 

Therefore, in this thesis, we have proposed a model-based approach for robust gait recognition where we extracted gait features from 2D body pose information. Body pose information is proven to be invariant to the change in clothing and carrying conditions. Additionally, as gait can be considered a time series of walking postures, body pose information also has a powerful capacity to capture the temporal pattern of gait. Therefore, the proposed method will be less affected by the variation of covariate factors. 




%-------------------------------------------------------------------------
\section{Deep Learning for Gait Recognition} \label{sec:deep_learning_gait_rec}
Modern deep learning-based algorithms such as CNN and RNN have recently gained increasing popularity while achieving outstanding performance in many computer vision tasks such as video classification~\cite{karpathy_14}, pose estimation~\cite{Cao_19}, and action recognition~\cite{Song_17, Du_15}, etc. Due to its powerful feature learning abilities, convolutional neural networks (\gls{cnn}s) have achieved great success in object recognition task in recent years. In contrast to methods presented in the previous sections in which features are handcrafted, CNNs implement a data-driven approach to find the best feature extractors based on the training data. Several CNN-based gait recognition methods~\cite{Wu_17, Shiraga_16, Wolf_16, Zhang_16, Yu_17, Yu_19} have been proposed which can automatically learn the robust gait features from the given training samples. Additionally, using CNNs, we now can execute feature extraction and perform recognition within a single framework. 

Wu \textit{et al.}~\cite{Wu_17} performed cross-view gait recognition by developing three convolutional layer network using the subject's GEI as input. Shiraga \textit{et al.}~\cite{Shiraga_16} designed an eight-layered CNN network, GEINet, for cross-view gait recognition. The network consisted of two sequential triplets of convolution, pooling, normalization layers, and two fully connected layers. The network was evaluated under a cross-view gait recognition setup using the OU-ISIR large population dataset.


In~\cite{Wolf_16}, Wolf \textit{et al.} used 3D convolutions for multi-view gait recognition by capturing the spatio-temporal features to find a general descriptor for human gait which is invariant to view angles, color, and different walking conditions. In order to make the model color invariant, they formulated a special type of input having three channels where the first channel of the input was the RGB-image converted to grey-scale, and for the second and third channel, the optical flow in X and Y directions were employed. The algorithm was evaluated on three different datasets namely the CMU Motion of Body (MoBo)~\cite{Gross_01}, the USF HumanID gait dataset~\cite{Sarkar_05}, and CASIA B dataset~\cite{Yu_06}.

A Siamese neural network-based gait recognition system has been developed in~\cite{Zhang_16} where GEI was feed as input. In~\cite{Yu_17}, Yu \textit{et al.} used generative adversarial nets to design a feature extractor in order to learn the invariant features. In~\cite{Yu_19}, they further improved the GAN-based method by adopting a multi-loss strategy to optimize the network to increase the inter-class distance and to reduce the intraclass distance at the same time.


%-------------------------------------------------------------------------
\section{Pose-Based Gait Recognition} \label{sec:pose_based_gait_rec}
Recently, there has been a huge interest in the study of deep learning-based approaches for the task of real-time pose estimation from image and video.~\cite{Wei_16, Cao_19}.  

To recognize multi-person pose, Cao \textit{et al.}~\cite{Cao_19} developed a deep CNN-based regression method to estimate the association between anatomical parts in the image. The architecture jointly learned the part locations and their association through the two branches of the same sequential prediction process. Furthermore, this bottom-up method achieved state-of-the-art performance in multiple benchmark datasets while achieving real-time performance. On the COCO 2016 key points challenge dataset, this architecture set the state-of-the-art performance, and the results achieved on the MPII multi-person dataset~\cite{Cai_16} significantly exceed the previous state-of-the-art methods. In this work, we employed their pretrained model on our experimental dataset to get accurate 2D coordinate information of the body parts. 

It is also worth mentioning that, in this work, we didn't use 3D pose data as our gait feature: firstly, computing 3D poses are computationally expensive, and secondly, most of the 3D pose estimation algorithms recover 3D poses from 2D RGB images which often require multiple views, and hence multiple cameras, rendering the technique unsuitable for surveillance. Again, recovering 3D pose from a single uncalibrated camera is inherently an ill-posed problem and which often causes large pose estimation errors. 

Again, recently, \gls{rnn}s have also achieved a promising performance in many sequence labeling tasks. The reason behind their effectiveness for sequence-based tasks lies in their ability to capture long-range dependencies in a temporal context from a sequence. \gls{rnn}s have also been successfully employed to achieve state-of-the-art results in many vision-based tasks like image captioning~\cite{Mao_15}, action recognition~\cite{Song_17, Du_15}, and gait recognition~\cite{Feng_16, Liao_17}.

With the advent of the pose-estimation algorithms in computer vision, the recognition of human gait based on body pose information has received much more attention due to its effective representation of gait features and robustness toward covariate conditions. Again, some of the most successful approaches for human gait recognition employ RNNs~\cite{Feng_16, Liao_17, Liao_19} to effectively model the temporal sequences of human pose data. For example, Feng \textit{et al.}~\cite{Feng_16} employed the human body joint heatmap to describe each frame. They fed the joint heatmap of consecutive frames to long short-term memory (\gls{lstm}). Their gait features are the hidden activation values of the last timestep. In contrast to their architecture, we employed the body pose information to extract a 50-D discriminative feature vector for each frame. 

In~\cite{Liao_17}, Liao \textit{et al.} constructed a pose-based temporal-spatial network (PTSN) to extract the spatial-temporal features which were robust to the clothing and carrying variations. They used two different kinds of networks for their model: LSTM to extract the temporal features from gait pose sequences and CNN to extract the spatial features from static gait pose frames. Finally, the two types of features were combined to capture the dynamic-static information of gait pose. They chose 6 effective body joints from OpenPose algorithm~\cite{Cao_19} as gait features and normalized them before feeding into the network. Experiments on CASIA B dataset showed that their method improved gait recognition rate greatly especially for the clothing condition variation.

In this thesis, we employed a similar approach to~\cite{Liao_17} for robust view-invariant gait recognition. However, instead of the raw normalized body joints, we extracted four different types of spatio-temporal features to form robust gait feature descriptors from OpenPose pose estimation algorithm. Again, in contrast to PTSN architecture which combined CNN with RNN architecture for capturing dynamic-static information, in this thesis, we performed gait recognition on a temporal domain employing only a simple but effective RNN-based network. 

Authors in~\cite{Liao_19}, introduced a new model-based gait recognition method, PoseGait, which employed the 3D body joint coordinates as input to their network as a discriminative and robust feature for gait recognition. They also fused four different kinds of features at the input level where some of the handcrafted features were also extracted based on human prior knowledge to form a spatio-temporal feature vector. Finally, they trained a 7-layer CNN architecture for CASIA B dataset and a 20-layer CNN architecture for CASIA E dataset to achieve better performance compared with 2D pose estimation. In their experiment, they found that instead of RNN, CNN can achieve a high recognition rate in gait recognition.

Our approach to gait recognition is similar to this PoseGait architecture. In this study, similar to~\cite{Liao_19} we extracted four different types of spatio-temporal features and fused them to form a discriminative gait feature vector. However, unlike~\cite{Liao_19} we extracted gait features from 2D pose information and their feature vector was also different from ours. Moreover, in this thesis, we only designed a simple but effective 2-layer \gls{bigru} architecture to model the discriminative gait features in a temporal domain in contrast to deep \gls{cnn} architecture as proposed in~\cite{Liao_19}. Although authors in~\cite{Liao_19} achieved high performance in cross-view gait setup, the main drawback of their architecture was that they had to design a different network for the different datasets. It was also difficult to train and computationally expensive in comparison to our proposed architecture.

Thus, the main idea of our proposed framework is to design low-dimensional spatio-temporal feature descriptors from 2D pose estimation for improved performance at a reduced computational cost. Our gait descriptor is a concatenation of four different types of the feature vector. We also build a simple but powerful network based on the (\gls{bigru}) which is proven to be effective in capturing and modeling the temporal dynamics of gait descriptors. For multi-view gait recognition, we also propose a two-stage network in which we first determine the walking direction, i.e., the view angle of the camera using a 3D convolutional network, and later identify the subject using the proposed 2-layer (\gls{bigru}) network trained on that view angle. 


