\chapter{Literature Review} \label{ch:literature_review}
Over the last two decades, several methods have been studied to develop a robust gait recognition system~\cite{Rida_19}. In this chapter, we briefly discuss some of these techniques which can be divided into the following two main classes.

\begin{itemize}
	\item \textbf{Sensor-based methods:} Wireless or wired sensors are attached to the joints of the subjects
	and the displacement are recorded with respect to a reference point. Joint angle trajectories and the distance between different parts of the body during	gait is then calculated and used for recognition. Pressure plates or carpet is also used to measure the pressure profile of the feet during gait. These methods are more prevalent in medical research and rehabilitation studies. The experiments are usually done in the laboratory setup and therefore has limited scope.
	
	\item \textbf{Image-based methods:} A video is recorded as the person walks along a preset trajectory without having any sensors attached to any part of the bod. The data can be recorded both indoor and outdoor using single or multiple cameras. This type of methods have much wider scope and applications. Image-based methods can be further subdivided into two categories, i.e., marker-based and markerless methods.
	
	\begin{itemize}
		\item \textbf{Marker-based methods: } Active or passive markers are placed on the body of the subject at different joints. This helps to detect and track the motion of desired joints in the video during gait motion. The subjects usually wear black and tight clothing and then reflective markers are placed on the joints. 
		
		\item \textbf{Markerless methods: } A video is recorded without using any markers and with normal clothing.
	\end{itemize}
\end{itemize}


The work proposed in this thesis falls into image based markerless category. There are two main approaches to person gait recognition in markerless systems. In the first approach, known as appearance-based approaches, no a priori human geometric shape model is assumed. While in case of model based approaches, a priori geometric shape model is available.

We will present a brief review of the previous works in both categories. However, with time these traditional handcrafted appearance-based techniques, as discussed in Section~\ref{sec:appearance_based_methods}, and model-based techniques, as discussed in Section~\ref{sec:model_based_methods}, are being shifted toward automated learning methods. In recent years, deep learning-based algorithms, e.g CNN and RNN, have been applied to gait recognition.  Section~\ref{sec:deep_learning_gait_rec} discuss some these methods which achieved state-of-the-art results. And in Section~\ref{sec:pose_based_gait_rec}, we review some of the recent pose-based gait recognition approaches which are closely related to our work. 




%-------------------------------------------------------------------------
\section{Appearance-based Methods} \label{sec:appearance_based_methods}
The appearance-based gait recognition methods first perform motion detection to segment the regions corresponding to the moving humans. Some form of shape analysis is then applied to these human image sequences to extract the gait signatures. Static body parameters such as lengths and widths of limbs, height of the person are extracted in some techniques and used to represent gait. Some works rely on the dynamic features that are extracted by shape changes and motion flow. Most of the previous work following this approach~\cite{Benabdelkader_02, Liu_04, Han_06, Bashir_09, Lam_11} used human silhouette masks as the main source of information and extracted features that show how these mask change. 

BenAbdelkader \textit{et. al.}~\cite{Benabdelkader_02} presented a parametric method for person identification based on the height and stride parameters of the gait from low resolution video sequences. A non-parametric background modeling approach was adopted for the segmentation of the moving objects. Foreground blobs were then tracked using spatial and temporal coherence. The height and stride parameters were determined from the extracted binary silhouettes. The experiments were performed on a database containing $ 45 $ subjects and an accuracy of $ 49\% $ was achieved by using both the stride and height parameters and only $21\%$ by using the stride parameter only. Although, they did not achieve a significant performance, yet their results show that stride and height parameters may be used as potential candidates for the gait recognition systems.

In~\cite{Liu_04}, Liu and Sarkar computed the average silhouette during the whole gait sequence. Their algorithm consists of three steps. In the first step, the background pixel statistics were calculated using the Mahalanobis distance and EM algorithm. The second step calculated the periodicity of the gait by simply counting the number of foreground pixels in the silhouette in each frame over time. The pixels belonging to the leg area were used to increase the sensitivity for determining the periodicity of the gait. In third and last step, the average silhouettes were computed. The similarity measure is defined as the negative of the median of the Euclidean distance between the averaged silhouettes from the probe and the gallery.

However, the most popular gait representation employed in appearance-based methods is gait energy image (GEI)~\cite{Han_06}, a binary mask computed through aligning and averaging the silhouettes over the complete gait cycle. Though there are many other alternatives for GEI, e.g., gait entropy image (GEnI)~\cite{Bashir_09}, gait flow image (GFI)~\cite{Lam_11}, and Chrono-gait Image (CGI)~\cite{Wang_12}, due to its in-sensitiveness of incidental silhouettes error, it has been considered as the most stable gait features.  It can achieve good performance under controlled and cooperative environments, but does not show robustness when the view angle and clothing condition change. 

In order to reduce drastic change of the shape of GEI, Huang \textit{et al.}~\cite{Huang_12} fused two new gait representation: shifted energy image and the gait structural profile to increase the robustness to some classes of structural variations. But, the performance of this method is not good enough due to the loss of temporal information while calculating GEI. 

To preserve temporal information, Wang \textit{et. al.}~\cite{Wang_12} modified the gait energy image and constructed Chrono-gait image to include temporal information. After gait period detection, they used local information entropy to obtain the gait contour from the silhouette images. Synthetic chrono gait images were also constructed to avoid over fitting due to smaller number of real chrono gait images. LDA and PCA were applied for dimensionality reduction. A comprehensive experimental evaluation was reported using 3 major gait databases. An average CMS value of $ 48.64\% $ and $ 66.81\% $ was achieved at rank 1 and rank 5 respectively using all 12 probe sets of HumanID database~\cite{Sarkar_05}. These results did not show marked improvements over related gait energy image method and were only marginally higher.


Therefore, appearance-based methods are sensitive to the covariate factors as the extraction of human silhouettes is affected by the changes in lighting. Moreover, when the shape of the human body and appearance change substantially, the performance of these methods severely degrades. Therefore, these methods are not completely robust toward these covariate change.



%-------------------------------------------------------------------------
\section{Model-based Methods} \label{sec:model_based_methods}
Model-based methods~\cite{Yam_04, Gu_10, Wagg_04} are often built with a structural and a motion model to capture both static as well as dynamic information of gait. The salient advantage of the these approach is that, in contrast to silhouette-based approaches, it can efficiently handle the covariate factors if the human bodies are correctly and high accurately modeled.

There have been a considerable amount of work on tracking human body based on the pose and body shape. However, these techniques have not caught much attention over the past years into the research community due to the fact that tracking human body is itself a challenging problem which involves very intensive computations. The geometrical model of human body is usually parameterized and tracking of the shape is achieved by establishing the correspondence between model configurations and image features. The most common methods for tracking include Kalman filter, dynamic Baysian network~\cite{Pavlovic_99} and condensation algorithm~\cite{Isard_98}. 

The model-based approaches generally extract gait features from either static parameters or relative motion of joint angles. The static parameters of human body such as torso height, leg length and stride are calculated from fitting the model in each frame and then further analyzing it for feature extraction. The joint angle trajectories are calculated using some methods and gait features are extracted from them. These approaches can also be distinguished by the dimension of the shape model which could be 2D or planar or a 3D model. The following paragraphs elaborates some of the popular model-based methods for human gait recognition.


Wagg and Nixon developed a model-based method based on the biomechanical analysis of walking people and used it for recognition~\cite{Wagg_04}. The image sequences were segmented to extract the moving regions and an articulated model is fitted to the edge by a hierarchical procedure. Motion estimation is performed by using a sinusoidal model for the leg and angle trajectories are extracted. The method is evaluated by using SOTON database~\cite{Shutler_04} and the feature vector is $63$ dimensional. A recognition rate of $84\%$ on the indoor dataset and $64\%$ for the outdoor dataset was achieved.


Yam \textit{et al.}~\cite{Yam_04} developed an automated model-based approach to recognize the people using walking as well as running gait. They used a modeling technique based on the concept of coupled oscillators and the underlying principles of human locomotion. The two approaches derive a phase-weighted Fourier Descriptor (FD) gait signature by automated non-invasive means. Assuming the gait symmetry, the same model was used to describe either leg since both perform the same motion but out of phase with each other by half a period. These motions operate in space and time satisfying the rules of spatial symmetry and temporal symmetry. This model of forced coupled oscillators is fitted to the image data extracting the lower leg motion in both walking and running gait. The gait features were derived from the magnitude and phase of FDs of thigh and lower leg rotation. A statistical analysis was also performed to find the most effective feature set. 


A 3D human body model consisting of $11$ body segments was developed by Gu \textit{et. al.}~\cite{Gu_10}. The head was represented by a sphere and other segments were cylindrical. The model contains $10$ joints with $24$ Degrees Of Freedom (DOF). The kinematic structure of the model was estimated by employing anthropometric constraints between ratios of limb lengths. After the body segmentation, adaptive particle filter was used to track the body segments. Gait features were extracted from pose parameters and joint position sequences. Two gait models were obtained from normalized joint sequence of the whole body and the normalized joint sequence of two legs using an exemplar-based Hidden Markov Model (HMM). Maximum a Posteriori (MAP) estimation was used for pattern classification. The test database consisted of multiple video streams of $12$ subjects that were simultaneously captured from multiple static calibrated cameras. Volumetric representation sequences were created using visual hull method after foreground extraction. An average recognition rate of $94.4\% $ was reported on the test database.

So, model-based approaches are generally invariant to various intraclass variations like clothing, carrying and view angle variations, etc. However, the main drawback of this approach is the extraction process of body parameters like height, knee, and torso are computationally expensive and highly dependent on the quality of the video.







%-------------------------------------------------------------------------
\section{Deep Learning for Gait Recognition} \label{sec:deep_learning_gait_rec}
Due to its powerful feature learning abilities, convolutional neural networks (\gls{cnn}s) have achieved great success in object recognition task in recent years. In contrast to methods presented in the previous sections in which features are handcrafted, CNNs implement a data-driven approach to find the best feature extractors based on the training data. Several CNN-based gait recognition methods~\cite{Wu_17, Shiraga_16, Wolf_16, Zhang_16, Yu_17, Yu_19} have been proposed which can automatically learn robust gait features from the given training samples. Additionally, using CNNs, we now can execute feature extraction and perform recognition within a single framework. 

Wu \textit{et al.}~\cite{Wu_17} performed cross-view gait recognition by developing three convolutional layer network using the subject's GEI as input. Shiraga \textit{et al.}~\cite{Shiraga_16} designed a eight-layered CNN network, GEINet, for cross-view gait recognition using GEI as input. The network consist of two sequential triplets of convolution, pooling, normalization layers, and two fully connected layers. The network was evaluated under cross-view gait recognition setup using the OU-ISIR large population dataset.


In~\cite{Wolf_16}, Wolf \textit{et al.} used 3D convolutions for multi-view gait recognition by capturing spatio-temporal features to find a general descriptor for human gait which is invariant to view angles, color and different walking conditions. In order to make the model color invariant they formulated special type of input having 3 channels where the first channel of the input image was the RGB-image converted to grey-scale and for second and third channel the optical flow in x and y were employed. The algorithm was evaluated on three different datasets namely the CMU Motion of Body (MoBo)~\cite{Gross_01}, the USF HumanID gait dataset~\cite{Sarkar_05} and CASIA B~\cite{Yu_06}.

A Siamese neural network-based gait recognition system has been developed in~\cite{Zhang_16} where GEI was feed as input. In~\cite{Yu_17}, Yu \textit{et al.} used generative adversarial nets to design a feature extractor in order to learn the invariant features. In~\cite{Yu_19}, they further improved the GAN-based method by adopting a multi-loss strategy to optimize the network to increase the inter-class distance and to reduce the intraclass distance at the same time.


%-------------------------------------------------------------------------
\section{Pose Estimation} \label{sec:pose_estimation}
In recent years, there has been a huge interest in the study of deep learning-based approaches for the task of real-time pose estimation from image and video.~\cite{Wei_16, Cao_19}.  

Authors in~\cite{Wei_16} introduced Convolutional Pose Machines (CPMs) for the task of articulated pose estimation. It consists of a sequence of convolutional networks that repeatedly produce 2D belief maps for the location to make a dense predictions at each image location. CPMs are completely differentiable and their multi-stage architecture can be trained end to end. 

To recognize multi-person pose, Cao \textit{et al.}~\cite{Cao_19} developed a deep CNN-based regression method to estimate the association between anatomical parts on the image. The architecture jointly learned the part of locations and their association through the two branches of the same sequential prediction process. Furthermore, this bottom-up method achieved state-of-the-art performance in multiple benchmark datasets while achieving real-time performance. On the COCO 2016 key points challenge dataset, this architecture set the state-of-the-art and the results significantly exceeds the previous state-of-the-art methods on the MPII multi-person dataset~\cite{Cai_16}. In this work, we employed their pretrained model on our experimental dataset to get an accurate 2D coordinate information of the body parts. 


%-------------------------------------------------------------------------
\section{Pose-based Gait Recognition} \label{sec:pose_based_gait_rec}
With the advent of the pose-estimation algorithms in computer vision, the recognition of human gait based on pose information has received much more attention~\cite{Feng_16, Liao_17, Liao_19} due to its effective representation of gait features and robustness toward covariate condition variations. Feng \textit{et al.}~\cite{Feng_16} used the human body joint heatmap to describe each frame. They fed the joint heatmap of consecutive frames to long short term memory (LSTM). Their gait features are the hidden activation values of the last timestep. 

In~\cite{Liao_17}, Liao \textit{et al.} constructed a pose-based temporal-spatial network (PTSN) to extract the spatial-temporal features of gait from 2D human pose information. 

Authors in~\cite{Liao_19}, introduced a model-based gait recognition method, PoseGait, which employed 3D body joint coordinates estimated from 2D pose as input their network as a feature for gait recognition. They also fused four different kinds of features at the input level where some of the handcrafted features were also extracted based on human prior knowledge to form a spatio-temporal feature vector. Finally they trained a 7-layer CNN architecture for CASIA B dataset and a 20-layer CNN architecture for CASIA E dataset to achieve better performance compared with 2D pose estimation. In their experiment, they found that instead of RNN, CNN can achieve high recognition rate in gait recognition.

Again, some of the most successful approaches for human action recognition employ RNNs~\cite{Song_17, Du_15} to effectively model the temporal sequences of human skeleton data. Song \textit{et al.}~\cite{Song_17} proposed an end-to-end spatial and temporal attention model with LSTM for human action recognition from skeleton data. In~\cite{Du_15}, Du \textit{et al.} proposed an end-to-end hierarchical RNN network for skeleton-based action recognition. They divided the human skeleton into five different parts and then separately feed them into five sub-networks. 

Our approach to gait recognition is similar to these approaches. In this study, we have proposed a simple RNN architecture that effectively models the discriminative gait features in a temporal domain. 


