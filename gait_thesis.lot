\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {3.1}{\ignorespaces List of effective joint-angle trajectories with corresponding body joints set for gait angular feature vector \relax }}{11}{table.caption.6}
\contentsline {table}{\numberline {3.2}{\ignorespaces Training summary of our proposed temporal network. \relax }}{16}{table.caption.9}
\contentsline {table}{\numberline {3.3}{\ignorespaces Training summary of our proposed 3D-CNN network. \relax }}{20}{table.caption.13}
\addvspace {10\p@ }
\contentsline {table}{\numberline {4.1}{\ignorespaces Comparison among different state-of-the-art gait recognition methods without view variation on all three view angles of CASIA-A dataset. It has been seen that, proposed method achieves best performance in correct class recognition rate on view angle ${45^{\circ }}$. Overall, it gets higher average recognition rates \textbf {98.3\%} and outperforms other state-of-the-art methods by a large margin. \relax }}{24}{table.caption.15}
\contentsline {table}{\numberline {4.2}{\ignorespaces Experimental setup for the CASIA B dataset. The dataset is divided into two different setups to organize two different types of experiment. the evaluation is subdivided into a gallery set and a probe set. Gallery set consists of the first 4 normal walking sequences of each subject and the probe set contains rest of the walking sequences \relax }}{25}{table.caption.18}
\contentsline {table}{\numberline {4.3}{\ignorespaces Correct class recognition rate (CCR) of proposed method in all three probe sets of CASIA B dataset. Here, column represents a specific view of gallery and probe set. It has been observed that the probe set of normal walking (\textit {ProbeNM}) achieves $ \textbf {99.41\%}$ average recognition rate while the ProbeBG and ProbeCL set achieve $ \textbf {97.80\%}$ and $\textbf {82.82\%}$ average recognition rates respectively. \relax }}{26}{table.caption.20}
\contentsline {table}{\numberline {4.4}{\ignorespaces Comparison between the proposed method and other state-of-the-art gait recognition methods in CASIA B dataset without view variation. It has been observed that the proposed method outperforms other methods in all three probe set of CASIA B dataset. As the proposed method doesn't depend on any body point higher than knee, it shows the robustness towards these covariate factors. It also achieves higher average correct class recognition rate (CCR) $\textbf {93.34\%}$ by outperforming other methods at a significant margin. \relax }}{26}{table.caption.22}
\contentsline {table}{\numberline {4.5}{\ignorespaces The average recognition rates for all three probe sets of CASIA B dataset. Each row represents the average value of all eleven probe angles at a specific gallery angle ($ \theta _g $) in all three probe sets. \relax }}{27}{table.caption.25}
\contentsline {table}{\numberline {4.6}{\ignorespaces Comparison among different state-of-the-art methods for gait recognition with view variation in all three probe sets of CASIA B dataset. Each row represents the average value of all the gallery view's average recognition rate. It has been seen that, similar to first experiment, the proposed method achieves higher performance in two different probe set (\textit {ProbeBG}, \textit {ProbeCL}) and comparable performance in normal walking with to other prevailing methods. \relax }}{28}{table.caption.27}
\contentsline {table}{\numberline {4.7}{\ignorespaces Comparison of our proposed method with the previous best results of cross-view gait recognition at different probe angles of CASIA B dataset by CCR (\%). The network was trained according to experimental setup B to have the same setup with other methods. \relax }}{29}{table.caption.29}
\contentsline {table}{\numberline {4.8}{\ignorespaces Comparison with other state-of-the-art methods on all three probe set of CASIA-B dataset in multi-view gait recognition. From the comparison, it is been observed that proposed two-stage network achieves higher average recognition rates in 8 of 11 different probe angles.\relax }}{30}{table.caption.30}
\contentsline {table}{\numberline {4.9}{\ignorespaces Correct walking direction identification rate (\%) of proposed 3D-CNN network on all three probe set of CASIA-B dataset. The network achieved \textbf {100\%} identification accuracy in all of the 11 view angles. \relax }}{30}{table.caption.31}
\addvspace {10\p@ }
\addvspace {10\p@ }
